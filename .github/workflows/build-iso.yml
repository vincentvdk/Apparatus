---
name: build-apparatus-iso
on:
  workflow_dispatch:
    inputs:
      upload-to-s3:
        description: "Upload to S3"
        required: false
        default: true
        type: boolean
  workflow_run:
    workflows: ["build-apparatus-os"]
    types:
      - completed

env:
  IMAGE_NAME: "apparatus-os"
  IMAGE_REGISTRY: "ghcr.io/${{ github.repository_owner }}"
  DEFAULT_TAG: "latest"
  TMPDIR: /mnt

concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build_iso:
    name: Build ISO
    runs-on: ubuntu-24.04
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}

    permissions:
      contents: read
      packages: read

    steps:
      - name: Free disk space
        run: |
          set -eux
          echo "=== Initial disk space ==="
          df -h /

          # Remove Docker images (~3-4GB)
          sudo docker image prune -a -f || :
          sudo docker system prune -a -f || :

          # Android SDK (~15GB)
          sudo rm -rf /usr/local/lib/android || :

          # .NET (~2GB)
          sudo rm -rf /usr/share/dotnet || :

          # Haskell/GHC (~5GB)
          sudo rm -rf /usr/local/.ghcup /opt/ghc || :

          # Swift (~2GB)
          sudo rm -rf /usr/share/swift || :

          # CodeQL (~5GB)
          sudo rm -rf /opt/hostedtoolcache/CodeQL || :

          # Go (~1.5GB)
          sudo rm -rf /opt/hostedtoolcache/go || :

          # Python/PyPy (~500MB)
          sudo rm -rf /opt/hostedtoolcache/PyPy /opt/hostedtoolcache/Python || :

          # Node.js (~400MB)
          sudo rm -rf /opt/hostedtoolcache/node || :

          # Ruby (~600MB)
          sudo rm -rf /opt/hostedtoolcache/Ruby || :

          # Azure CLI (~700MB)
          sudo rm -rf /opt/az /usr/share/az_* || :

          # PowerShell (~300MB)
          sudo rm -rf /opt/microsoft /usr/local/share/powershell || :

          # AWS tools (~1GB)
          sudo rm -rf /usr/local/aws-sam-cli /usr/local/aws-cli || :

          # Julia (~500MB)
          sudo rm -rf /usr/local/julia* || :

          # Miniconda (~500MB)
          sudo rm -rf /usr/share/miniconda || :

          # Google Cloud SDK (~1GB)
          sudo rm -rf /usr/lib/google-cloud-sdk || :

          # Heroku (~350MB)
          sudo rm -rf /usr/local/lib/heroku || :

          # Chromium/browsers (~1.5GB)
          sudo rm -rf /usr/local/share/chromium || :
          sudo apt purge -y firefox google-chrome-stable microsoft-edge-stable || :

          # vcpkg (~200MB)
          sudo rm -rf /usr/local/share/vcpkg || :

          # Gradle (~200MB)
          sudo rm -rf /usr/share/gradle-* || :

          # Various CLI tools
          sudo rm -rf \
            /usr/local/bin/aliyun \
            /usr/local/bin/azcopy \
            /usr/local/bin/bicep \
            /usr/local/bin/cmake-gui \
            /usr/local/bin/cpack \
            /usr/local/bin/helm \
            /usr/local/bin/hub \
            /usr/local/bin/kubectl \
            /usr/local/bin/minikube \
            /usr/local/bin/packer \
            /usr/local/bin/pulumi* \
            /usr/local/bin/sam \
            /usr/local/bin/stack \
            /usr/local/bin/terraform \
            /usr/local/bin/oc \
            /usr/local/lib/node_modules || :

          # Clean apt cache
          sudo apt autoremove -y
          sudo apt clean

          # Remove swap file to reclaim ~4GB
          sudo swapoff -a || :
          sudo rm -f /swapfile /mnt/swapfile || :

          echo "=== Disk space after cleanup ==="
          df -h /

          # Prepare temp storage on /mnt (has ~70GB available)
          sudo mkdir -p /mnt/tmp /mnt/var_tmp /mnt/containers
          sudo chmod 1777 /mnt/tmp /mnt/var_tmp /mnt/containers

          # Redirect /var/tmp to /mnt (skopeo/podman uses /var/tmp for blob storage)
          sudo rm -rf /var/tmp
          sudo ln -s /mnt/var_tmp /var/tmp

          # Also redirect /tmp to /mnt
          sudo rm -rf /tmp
          sudo ln -s /mnt/tmp /tmp

          echo "TMPDIR=/mnt/tmp" >> $GITHUB_ENV
          echo "TITANOBOA_WORKDIR=/mnt/titanoboa" >> $GITHUB_ENV
          sudo mkdir -p /mnt/titanoboa
          sudo chmod 1777 /mnt/titanoboa

          # Configure podman/skopeo to use /mnt for storage (fix heredoc indentation)
          sudo mkdir -p /etc/containers /mnt/containers/storage /mnt/containers/run
          sudo tee /etc/containers/storage.conf > /dev/null <<'EOF'
          [storage]
          driver = "overlay"
          runroot = "/mnt/containers/run"
          graphroot = "/mnt/containers/storage"
          [storage.options.overlay]
          mount_program = "/usr/bin/fuse-overlayfs"
          EOF
          sudo sed -i 's/^          //' /etc/containers/storage.conf
          echo "Storage config:"
          cat /etc/containers/storage.conf

          # Also configure for root user
          sudo mkdir -p /root/.config/containers
          sudo cp /etc/containers/storage.conf /root/.config/containers/storage.conf

          # Set container storage env vars
          echo "CONTAINERS_STORAGE_CONF=/etc/containers/storage.conf" >> $GITHUB_ENV

          echo "=== Final disk space ==="
          df -h

      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build ISO
        id: build
        uses: ublue-os/titanoboa@main
        with:
          image-ref: ${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}
          builder-distro: fedora

      - name: Upload to S3
        if: inputs.upload-to-s3 == true || github.event_name == 'workflow_run'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.HETZNER_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.HETZNER_S3_SECRET_KEY }}
        run: |
          pip install awscli

          # Find the ISO file
          ISO_FILE=$(find ${{ steps.build.outputs.output-path }} -name "*.iso" | head -1)

          aws s3 cp "$ISO_FILE" \
            s3://${{ secrets.HETZNER_S3_BUCKET }}/apparatus-os-latest.iso \
            --endpoint-url "https://${{ secrets.HETZNER_S3_ENDPOINT }}"

          echo "ISO uploaded successfully"

      - name: Upload ISO artifact (fallback)
        if: inputs.upload-to-s3 != true && github.event_name != 'workflow_run'
        uses: actions/upload-artifact@v4
        with:
          name: apparatus-os-iso
          path: ${{ steps.build.outputs.output-path }}
          retention-days: 7
          compression-level: 0
